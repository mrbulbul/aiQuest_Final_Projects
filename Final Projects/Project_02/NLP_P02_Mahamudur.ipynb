{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6bb551",
   "metadata": {},
   "source": [
    "# Title: Sentiment Analysis on Amazon Product Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99858734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import string\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94667559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  This is a one of the best apps acording to a b...         1\n",
       "1  This is a pretty good version of the game for ...         1\n",
       "2  this is a really cool game. there are a bunch ...         1\n",
       "3  This is a silly game and can be frustrating, b...         1\n",
       "4  This is a terrific game on any pad. Hrs of fun...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"amazon.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e739d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025973e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   reviewText  20000 non-null  object\n",
      " 1   Positive    20000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b855b7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "Positive      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b8b3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewText, Positive]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea37fe4",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974c3d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a one of the best apps acording to a bunch of people and I agree it has bombs eggs pigs TNT king pigs and realustic stuff'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870da59b",
   "metadata": {},
   "source": [
    "## Lower-casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06910763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0194b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is a terrific game on any pad. hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  this is a one of the best apps acording to a b...         1\n",
       "1  this is a pretty good version of the game for ...         1\n",
       "2  this is a really cool game. there are a bunch ...         1\n",
       "3  this is a silly game and can be frustrating, b...         1\n",
       "4  this is a terrific game on any pad. hrs of fun...         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae3c50",
   "metadata": {},
   "source": [
    "## Removing punctuation and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b00c027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\IT\n",
      "[nltk_data]     BD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopword = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eecd23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one best apps acording bunch people agree bomb...\n",
       "1        pretty good version game free lots different l...\n",
       "2        really cool game bunch levels find golden eggs...\n",
       "3        silly game frustrating lots fun definitely rec...\n",
       "4        terrific game pad hrs fun grandkids love great...\n",
       "                               ...                        \n",
       "19995    app fricken stupidit froze kindle wont allow p...\n",
       "19996    please add need neighbors ginger1016 thanks bu...\n",
       "19997    love game awesome wish free stuff houses didnt...\n",
       "19998    love love love app side fashion story fights w...\n",
       "19999    game rip list things make betterbull first nee...\n",
       "Name: reviewText, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Checking if the input is a string\n",
    "        # Remove punctuation\n",
    "        remove_punc = [char for char in text if char not in string.punctuation]\n",
    "        clean_words = ''.join(remove_punc)  # Char joining\n",
    "\n",
    "        # Remove stopwords\n",
    "        text = ' '.join([word for word in clean_words.split() if word.lower() not in stopword])\n",
    "        \n",
    "    return text\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "df['reviewText']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501fcd5",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b5f398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one best apps acording bunch people agree bomb...\n",
       "1        pretty good version game free lot different le...\n",
       "2        really cool game bunch level find golden egg s...\n",
       "3        silly game frustrating lot fun definitely reco...\n",
       "4        terrific game pad hr fun grandkids love great ...\n",
       "                               ...                        \n",
       "19995    app fricken stupidit froze kindle wont allow p...\n",
       "19996    please add need neighbor ginger1016 thanks bun...\n",
       "19997    love game awesome wish free stuff house didnt ...\n",
       "19998    love love love app side fashion story fight wo...\n",
       "19999    game rip list thing make betterbull first need...\n",
       "Name: reviewText, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    if isinstance(text, str):  # Checking if the input is a string\n",
    "        lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "        return lemmatized_text\n",
    "    else:\n",
    "        return text  # Returning non-string values as is\n",
    "df['reviewText'] = df['reviewText'].apply(lemmatize_text)\n",
    "df['reviewText']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93084f77",
   "metadata": {},
   "source": [
    "## Splitting into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a035b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'].fillna('', inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"reviewText\"], df[\"Positive\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8992f291",
   "metadata": {},
   "source": [
    "## TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "318cc17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0e334",
   "metadata": {},
   "source": [
    "## Model Selection, Training and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41bbd8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.8817\n",
      "Precision: 0.8837\n",
      "Recall: 0.9689\n",
      "F1-Score: 0.9243\n",
      "[[ 953  571]\n",
      " [ 139 4337]]\n",
      "Random Forest Results:\n",
      "Accuracy: 0.8595\n",
      "Precision: 0.8549\n",
      "Recall: 0.9777\n",
      "F1-Score: 0.9121\n",
      "[[ 781  743]\n",
      " [ 100 4376]]\n",
      "Support Vector Machine Results:\n",
      "Accuracy: 0.8853\n",
      "Precision: 0.8878\n",
      "Recall: 0.9687\n",
      "F1-Score: 0.9265\n",
      "[[ 976  548]\n",
      " [ 140 4336]]\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression()),\n",
    "    (\"Random Forest\", RandomForestClassifier()),\n",
    "    (\"Support Vector Machine\", SVC()),\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    \n",
    "    #Training the model\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    #Evaluating performance\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d49934e",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dcdb0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunned Random Forest Results:\n",
      "Accuracy: 0.7463\n",
      "Precision: 0.7462\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.8547\n",
      "[[   2 1522]\n",
      " [   0 4476]]\n",
      "Best Random Forest Parameters: {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Hyperparameter Tuning\n",
    "random_forest = RandomForestClassifier()\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [5, 10, 15],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "grid_search_rf = GridSearchCV(random_forest, param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train_vec, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Evaluating the best Random Forest model\n",
    "y_pred = best_rf.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Tunned Random Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2be93382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunned SVM Results:\n",
      "Accuracy: 0.8902\n",
      "Precision: 0.9058\n",
      "Recall: 0.9517\n",
      "F1-Score: 0.9282\n",
      "[[1081  443]\n",
      " [ 216 4260]]\n",
      "Best SVM Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# SVM Hyperparameter Tuning\n",
    "svm = SVC()\n",
    "param_grid_svm = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train_vec, y_train)\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "# Evaluating the best SVM model\n",
    "y_pred = best_svm.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Tunned SVM Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Best SVM Parameters:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def2943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
